<!DOCTYPE html>
<html>
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="referrer" content="no-referrer">
        <title>Dust's Blog</title>
        <meta charset="utf-8" />

        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/muicss@0.9.41/dist/css/mui.min.css"
              integrity="sha256-oX1CoieDE574GYL7nKAFSFOt8BdQzeKvATYS4VqFqNw=" crossorigin="anonymous">
        <link href="/theme/css/main.css" rel="stylesheet">
        <link href="/theme/css/highlight.css" rel="stylesheet">
</head>

<body id="index" class="home">
  <div id="container" class="mui-container">
        <header id="banner" class="body">
                <h1><a href="/">Dust's Blog <strong></strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li>
              <div class="index-cat"><a href="/">Index</a></div>
            </li>
              <li class="active">
                <div  class="last-cat" >
                  <a href="/category/tech.html">Tech</a>
                </div>
              </li>
        </ul></nav><!-- /#menu -->
<section id="content" class="mui--divider-top">
<h2 class="mui--text-center">Category - Tech </h2>

<ol id="post-list">
        <li><article class="hentry ">
                <header> <h2 class="entry-title"><a href="/raspberry-downloader.html" rel="bookmark">利用树莓派进行挂机下载</a></h2> </header>
<footer class="post-info">
    <div class="category-info">
        📁 <a href="/category/tech.html">Tech</a>
    </div>
    <p class="tag-info">
 📌             <a href="/tag/raspberry.html">raspberry</a>    </p>
    <time class="published" datetime="2019-09-07T18:59:00+08:00">
      🖊️ 2019-09-07 18:59:00
    </time>
  </footer><!-- /.post-info -->                <div class="entry-content"> <p>一直有买 NAS 做下载姬的想法，但见过太多人买回家吃灰的例子，而且我的松鼠症并不严重，所以犹豫着。直到听闻树莓派4代发售，价格比 NAS 便宜，正好家里也有闲置 U 盘，思来想去，果然还是树莓派比较适合老子.jpg</p>
<h2>1. 准备工作</h2>
<p>在淘宝找到相关店家，根据自己的需要选择相应套餐，因为需要预订，大概一周后到货。</p>
<p>树莓派到手后，先将 Raspbian 系统镜像写入 micro SD 卡，推荐使用 <a href="https://www.raspberrypi.org/documentation/installation/installing-images/README.md">官方教程</a> 提到的 balenaEtcher，十分方便。</p>
<p><img alt="balenaEtcher" src="images/etchcer.jpg"></p>
<p>之后配置远程 SSH 和 wifi（如果选择直接在树莓派上外接显示器和键盘就不用进行这一步），简单来说就是在根目录新建 SSH 文件和 wpa_supplicant.conf 文件，文件内容参考 <a href="https://www.raspberrypi.org/documentation/configuration/wireless/headless.md">官方教程</a> 。</p>
<p>配置好后，插入 SD …</p> </div><!-- /.entry-content -->
                <div class="read-more">
                    <a class="read-more-link" href="/raspberry-downloader.html">>> Read More</a>
                </div>
        </article></li>
        <li><article class="hentry mui--divider-top ">
                <header> <h2 class="entry-title"><a href="/phpMyAdmin-docker-config.html" rel="bookmark">phpMyAdmin Docker 简单配置</a></h2> </header>
<footer class="post-info">
    <div class="category-info">
        📁 <a href="/category/tech.html">Tech</a>
    </div>
    <p class="tag-info">
 📌             <a href="/tag/docker.html">docker</a>,            <a href="/tag/phpmyadmin.html">phpMyAdmin</a>    </p>
    <time class="published" datetime="2019-06-21T16:43:41+08:00">
      🖊️ 2019-06-21 16:43:41
    </time>
  </footer><!-- /.post-info -->                <div class="entry-content"> <p>phpMyAdmin（以下简称 PMA ）的数据字典（Data Dictionary）对我来说是一个比较有用的功能（实际上我只用这个功能...），可以以网页形式浏览所有表、视图、字段、索引、注释等，在一个有数百张表的数据库中可以快速检索所需信息。</p>
<p><img alt="image" src="/images/pma_data_dict.png"></p>
<p>利用 Docker 可以方便快速地在本地部署 PMA。</p>
<p>下载</p>
<p><code>docker pull phpmyadmin/phpmyadmin</code></p>
<p>运行</p>
<p><code>docker run --name PMA -d -p 8080:80 --restart=always -e PMA_ARBITRARY=1 -v /path/to/phpmyadmin/config.user.inc.php:/etc/phpmyadmin/config.user.inc …</code></p> </div><!-- /.entry-content -->
                <div class="read-more">
                    <a class="read-more-link" href="/phpMyAdmin-docker-config.html">>> Read More</a>
                </div>
        </article></li>
        <li><article class="hentry mui--divider-top ">
                <header> <h2 class="entry-title"><a href="/encrypted-compression-javascript-analysis.html" rel="bookmark">数据抓取实践：对加密参数及压缩混淆JS的逆向分析</a></h2> </header>
<footer class="post-info">
    <div class="category-info">
        📁 <a href="/category/tech.html">Tech</a>
    </div>
    <p class="tag-info">
 📌             <a href="/tag/python.html">python</a>,            <a href="/tag/frontend.html">frontend</a>,            <a href="/tag/crawler.html">crawler</a>    </p>
    <time class="published" datetime="2018-05-15T18:40:27+08:00">
      🖊️ 2018-05-15 18:40:27
    </time>
  </footer><!-- /.post-info -->                <div class="entry-content"> <p>之前在 V 站上看到一个帖子，内容是楼主想抓取数据的网站做了参数加密，不知如何解密。刚好最近有点空闲时间，可以尝试解密一下网页参数，而且很久没练手了。</p>
<p>文中会介绍几种分析技巧，需要一点前端知识（总感觉在前端做防爬没什么意义，因为源码都是公开的）。文末附上爬虫 Demo 验证，虽然对于这个案例来说使用 Selenium 可能才是合适的解决方法，但<del>暴力破解才是男人的浪漫！</del> ...嗯本文的重点只是在于分析解密的过程。有些图片因代码过长未包含在内，意会即可。</p>
<h2>1. 一夫当关 - XHR Breakpoints</h2>
<p>网站是<a href="https://www.qimai.cn/rank/">七麦数据</a>。我们要抓取的内容是页面上的 App Store 排行榜数据。</p>
<p>通过分析网络请求我们可以发现，榜单数据是通过 Ajax 请求来获取的。返回的数据格式是明文 Json。</p>
<p><img alt="image" src="/images/1.png"></p>
<p>请求参数如下：</p>
<div class="highlight"><pre><span></span><span class="n">analysis</span><span class="o">:</span> <span class="n">dDB4Fi8wUEF</span><span class="o">...(</span><span class="err">太长，略</span><span class="o">)</span>
<span class="n">brand</span><span class="o">:</span> <span class="n">all</span>
<span class="n">country</span><span class="o">:</span> <span class="n">cn</span>
<span class="n">device</span><span class="o">:</span> <span class="n">iphone …</span></pre></div> </div><!-- /.entry-content -->
                <div class="read-more">
                    <a class="read-more-link" href="/encrypted-compression-javascript-analysis.html">>> Read More</a>
                </div>
        </article></li>
        <li><article class="hentry mui--divider-top ">
                <header> <h2 class="entry-title"><a href="/scrapy-start-requests-trap.html" rel="bookmark">Scrapy 暗坑之 start_requests</a></h2> </header>
<footer class="post-info">
    <div class="category-info">
        📁 <a href="/category/tech.html">Tech</a>
    </div>
    <p class="tag-info">
 📌             <a href="/tag/python.html">python</a>,            <a href="/tag/scrapy.html">scrapy</a>    </p>
    <time class="published" datetime="2018-03-01T14:03:42+08:00">
      🖊️ 2018-03-01 14:03:42
    </time>
  </footer><!-- /.post-info -->                <div class="entry-content"> <p>众所周知，Scrapy 默认会过滤重复的 URL，不会重复抓取相同的 URL，除非显式指定。</p>
<p>于是随便写了一个爬图片地址的小虫，然而不知道为什么总会爬两次 baidu 首页，你能看出错在哪里吗？</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ImageSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;images&quot;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;www.baidu.com&quot;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://www.baidu.com/&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//img/@src&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
            <span class="n">image_item</span> <span class="o">=</span> <span class="n">ImageItem</span><span class="p">()</span>
            <span class="n">image_item</span><span class="p">[</span><span class="s1">&#39;img_url&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
            <span class="k">yield …</span></pre></div> </div><!-- /.entry-content -->
                <div class="read-more">
                    <a class="read-more-link" href="/scrapy-start-requests-trap.html">>> Read More</a>
                </div>
        </article></li>
</ol><!-- /#posts-list -->
</section><!-- /#content -->

        <footer id="contentinfo" class="body mui--divider-top">
          <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh">
            <img id="cc" src="/images/cc.80x15.png" alt="CC BY-SA"></a>
                <address id="about" class="vcard body">
                Powered by <a href="https://github.com/getpelican/pelican">Pelican</a>.
                Theme <a href="/">Autism</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
  </div>

  <script defer src="/theme/js/image.js"></script>
</body>
</html>